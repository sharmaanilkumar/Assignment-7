{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment7.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3mRHA5OF2_qd"
      },
      "source": [
        "In this notebook I will show how to generate text with usage of Recurrent Neural Network. I will use Shakespare work for that exercise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "djbpKERP3ZCI"
      },
      "source": [
        "### Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fVdX-5sz2wcn",
        "outputId": "63e675a3-dc07-4211-b257-185f825012ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "!pip install tqdm\n",
        "from tqdm import tqdm\n",
        "import urllib\n",
        "\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import re\n",
        "import random as rn\n",
        "import numpy as np\n",
        "\n",
        "# Randomness control\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "RANDOM_SEED = 3939\n",
        "np.random.seed(RANDOM_SEED)\n",
        "rn.seed(RANDOM_SEED)\n",
        "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, \n",
        "                              inter_op_parallelism_threads=1)\n",
        "\n",
        "tf.set_random_seed(RANDOM_SEED)\n",
        "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "keras.backend.set_session(sess)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bIqOOeuK60BT",
        "colab": {}
      },
      "source": [
        "DATA_URL = \"http://www.gutenberg.org/cache/epub/1041/pg1041.txt\"\n",
        "DATA_FILENAME = \"sonnets.txt\"\n",
        "\n",
        "SEQ = 100\n",
        "feature = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ilGm0hMR8Jq8"
      },
      "source": [
        "### Fetch Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g_oi_r9r8CSb",
        "outputId": "b0657429-4672-4a30-9627-276eb19d6d7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class DLProgress(tqdm):\n",
        "  last_block = 0\n",
        "\n",
        "  def hook(self, block_num=1, block_size=1, total_size=None):\n",
        "    self.total = total_size\n",
        "    self.update((block_num - self.last_block) * block_size)\n",
        "    self.last_block = block_num\n",
        "\n",
        "with DLProgress(unit=\"B\", unit_scale=True, miniters=1, desc=\"Shakespeare's Sonnets\") as pbar:\n",
        "  urlretrieve(DATA_URL, DATA_FILENAME, pbar.hook)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shakespeare's Sonnets: 123kB [00:00, 440kB/s]                             \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g0LNrTfM8cXv"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jlyq9Ajd8YLI",
        "colab": {}
      },
      "source": [
        "with open(DATA_FILENAME, \"r\") as file:\n",
        "  data = file.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7bqXF4vo8mBO",
        "colab": {}
      },
      "source": [
        "start_index = 740\n",
        "end_index = re.search(\"Love's fire heats water, water cools not love.\", data)\n",
        "end_index = end_index.end()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BxBOT_SMATg8",
        "colab": {}
      },
      "source": [
        "data_cleaned = data[start_index:end_index]\n",
        "# print(data_cleaned)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pIkgLUlKMm05"
      },
      "source": [
        "To lower case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XKmTWQ_CMoZx",
        "colab": {}
      },
      "source": [
        "data_cleaned = data_cleaned.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iyvZ4MmlE9Td"
      },
      "source": [
        "Number of characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jUjyAOGKE87_",
        "outputId": "8971f156-b89a-4512-d076-6b490618e077",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(data_cleaned))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100228\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2-qUypWYNo_t"
      },
      "source": [
        "Reducing the size of dataset for saving computation time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uCT9KAzwNsRR",
        "colab": {}
      },
      "source": [
        "split_index = int(0.5 * len(data_cleaned))\n",
        "data_cleaned = data_cleaned[:split_index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m9fJFZ_hCOAr"
      },
      "source": [
        "### Preprocessing the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kDSUaJTuC8VC"
      },
      "source": [
        "Mapping every unique character to integer id"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a6dl72TjAZXr",
        "colab": {}
      },
      "source": [
        "characters = sorted(list(set(data_cleaned)))\n",
        "id_to_character = {i:char for i, char in enumerate(characters)}\n",
        "character_to_id = {char:i for i, char in enumerate(characters)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqo9y4YsbxOZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff0c095b-baa7-418d-c916-d9cc91c0e736"
      },
      "source": [
        "totalchar = len(data_cleaned)\n",
        "print(totalchar)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QWv0Jqg0C4bn",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zmUVGlHpFleW"
      },
      "source": [
        "Creating the  input and output sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tBF0rVY6Dn55",
        "outputId": "319f62f3-718d-48dd-b64c-c25ef34ba230",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "def data_to_sequence(data, data_to_id_dict):\n",
        "  seq_Xs, seq_Ys = list(), list()\n",
        "\n",
        "  for i in range(0, len(data) - SEQ):\n",
        "    seq = data[i:i + SEQ]\n",
        "    label = data[i + SEQ]\n",
        "    \n",
        "    seq_Xs.append([data_to_id_dict[char] for char in seq])\n",
        "    seq_Ys.append(data_to_id_dict[label])\n",
        "  \n",
        "  return seq_Xs, seq_Ys\n",
        "\n",
        "seq_Xs, seq_ys = data_to_sequence(data_cleaned, character_to_id)\n",
        "\n",
        "for x, y in zip(seq_Xs[0:2], seq_ys[0:2]):\n",
        "  print(x, y)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 18, 0, 0, 1, 1, 15, 27, 24, 22, 1, 15, 10, 18, 27, 14, 28, 29, 1, 12, 27, 14, 10, 29, 30, 27, 14, 28, 1, 32, 14, 1, 13, 14, 28, 18, 27, 14, 1, 18, 23, 12, 27, 14, 10, 28, 14, 4, 0, 1, 1, 29, 17, 10, 29, 1, 29, 17, 14, 27, 14, 11, 34, 1, 11, 14, 10, 30, 29, 34, 3, 28, 1, 27, 24, 28, 14, 1, 22, 18, 16, 17, 29, 1, 23, 14, 31, 14, 27, 1, 13, 18, 14, 4, 0, 1, 1, 11, 30, 29] 1\n",
            "[18, 0, 0, 1, 1, 15, 27, 24, 22, 1, 15, 10, 18, 27, 14, 28, 29, 1, 12, 27, 14, 10, 29, 30, 27, 14, 28, 1, 32, 14, 1, 13, 14, 28, 18, 27, 14, 1, 18, 23, 12, 27, 14, 10, 28, 14, 4, 0, 1, 1, 29, 17, 10, 29, 1, 29, 17, 14, 27, 14, 11, 34, 1, 11, 14, 10, 30, 29, 34, 3, 28, 1, 27, 24, 28, 14, 1, 22, 18, 16, 17, 29, 1, 23, 14, 31, 14, 27, 1, 13, 18, 14, 4, 0, 1, 1, 11, 30, 29, 1] 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SiXNWafRHjpu"
      },
      "source": [
        "Assembling the  train_X, train_y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IBKmxU0dG3OZ",
        "colab": {}
      },
      "source": [
        "train_X = np.reshape(seq_Xs, (len(seq_Xs), SEQ, feature))\n",
        "train_y = keras.utils.to_categorical(seq_ys)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z3UZ2KHQJXzD"
      },
      "source": [
        "Normalize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ty7Bcwp9JSAc",
        "colab": {}
      },
      "source": [
        "train_X = train_X / float(len(characters))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mP9_6A17Jp1h"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T6pgeXxbLP8A"
      },
      "source": [
        "Structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6ymgsOy_JpWU",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(800, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(LSTM(800))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(train_y.shape[1], activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Sxwsw9GfLVPx"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IOndk2UQJoUQ",
        "outputId": "f3be46ea-6699-47d9-e373-db756eaa3bc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        }
      },
      "source": [
        "history = model.fit(train_X, train_y, \n",
        "                    epochs = 20, \n",
        "                    batch_size = 128, \n",
        "                    verbose = 1, \n",
        "                    shuffle = False)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "50014/50014 [==============================] - 156s 3ms/step - loss: 2.9262\n",
            "Epoch 2/20\n",
            "50014/50014 [==============================] - 153s 3ms/step - loss: 2.6267\n",
            "Epoch 3/20\n",
            "50014/50014 [==============================] - 154s 3ms/step - loss: 2.4888\n",
            "Epoch 4/20\n",
            "50014/50014 [==============================] - 153s 3ms/step - loss: 2.3933\n",
            "Epoch 5/20\n",
            "50014/50014 [==============================] - 154s 3ms/step - loss: 2.3111\n",
            "Epoch 6/20\n",
            "50014/50014 [==============================] - 153s 3ms/step - loss: 2.2318\n",
            "Epoch 7/20\n",
            "50014/50014 [==============================] - 154s 3ms/step - loss: 2.1572\n",
            "Epoch 8/20\n",
            "50014/50014 [==============================] - 153s 3ms/step - loss: 2.0826\n",
            "Epoch 9/20\n",
            "50014/50014 [==============================] - 154s 3ms/step - loss: 2.0158\n",
            "Epoch 10/20\n",
            "50014/50014 [==============================] - 153s 3ms/step - loss: 1.9267\n",
            "Epoch 11/20\n",
            "50014/50014 [==============================] - 154s 3ms/step - loss: 1.8223\n",
            "Epoch 12/20\n",
            "50014/50014 [==============================] - 153s 3ms/step - loss: 1.7165\n",
            "Epoch 13/20\n",
            "50014/50014 [==============================] - 154s 3ms/step - loss: 1.6103\n",
            "Epoch 14/20\n",
            "50014/50014 [==============================] - 153s 3ms/step - loss: 1.5136\n",
            "Epoch 15/20\n",
            "50014/50014 [==============================] - 153s 3ms/step - loss: 1.4543\n",
            "Epoch 16/20\n",
            "50014/50014 [==============================] - 153s 3ms/step - loss: 1.3480\n",
            "Epoch 17/20\n",
            "50014/50014 [==============================] - 153s 3ms/step - loss: 1.2558\n",
            "Epoch 18/20\n",
            "50014/50014 [==============================] - 153s 3ms/step - loss: 1.1456\n",
            "Epoch 19/20\n",
            "50014/50014 [==============================] - 154s 3ms/step - loss: 1.0668\n",
            "Epoch 20/20\n",
            "50014/50014 [==============================] - 153s 3ms/step - loss: 0.9759\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q4rl5NGoObKc"
      },
      "source": [
        "### Text generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hgftbq3hLeFx",
        "colab": {}
      },
      "source": [
        "string_mapped = seq_Xs[100]\n",
        "full_string = [id_to_character[value] for value in string_mapped]\n",
        "\n",
        "for i in range(1000):\n",
        "    x = np.reshape(string_mapped,(1,len(string_mapped), 1))\n",
        "    x = x / float(len(characters))\n",
        "    \n",
        "    pred_index = np.argmax(model.predict(x, verbose=0))\n",
        "    seq = [id_to_character[value] for value in string_mapped]\n",
        "    full_string.append(id_to_character[pred_index])\n",
        "\n",
        "    string_mapped.append(pred_index)\n",
        "    string_mapped = string_mapped[1:len(string_mapped)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DzWxKTJZOOpM",
        "colab": {}
      },
      "source": [
        "generated_text = \"\"\n",
        "for char in full_string:\n",
        "    generated_text += char"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rJi2ZmjqP35E",
        "outputId": "05dde8a6-dcf9-4c01-e2b7-62fdafa5831c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "print(generated_text)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " as the riper should by time decease,\n",
            "  his tender heir might bear his memory:\n",
            "  but thou, contracted att thine ewas,\n",
            "  and oe thin werd toills sorte     that in your sweet thoughts would be toowe,\n",
            "    the soilk wo diaue, io shose what isow yot\n",
            "    so long as mee shal thou sead str she geart;\n",
            "    ior the deauh, there all thei my love sheer,\n",
            "    and thes shall leve, to thow what whou wealt sealed\n",
            "isew,\n",
            "  why should pe beauty what thou sele'stm fraen,\n",
            "  so should me live, now nose to bre io teed\n",
            "  that you to love that weil th maye ir blow\n",
            "\n",
            "   this thou de thy self wo bre, tr all away.\n",
            "\n",
            "  lxxvi\n",
            "\n",
            "  why is my love still me ne the day,\n",
            "  the oavt tooe pidat see mame defence\n",
            "  and art move dongonss mo a toifk seee;\n",
            "  to, live you thale io my love and treek,\n",
            "  when i peave and the mank the sures wo dod,\n",
            "  sr fir thou dester the world say see my pleasure,\n",
            "  sowerit tf thee to be remembered.\n",
            "    t! nest touerift in the world saee broteer;\n",
            "  when i perhees the world sast to mes iidht,\n",
            "  so should mn the torld say see my pleasure:\n",
            "  sowesuiog to gestles of aw yea memdsh drime\n",
            "  thy ounwand tout\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wp11ekZ4-HxC",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}